{
  "1": {
    "inputs": {
      "ckpt_name": "Trace.safetensors"
    },
    "class_type": "CheckpointLoaderSimple",
    "_meta": {
      "title": "Load Checkpoint"
    }
  },
  "2": {
    "inputs": {
      "stop_at_clip_layer": -1,
      "clip": [
        "1",
        1
      ]
    },
    "class_type": "CLIPSetLastLayer",
    "_meta": {
      "title": "CLIP Set Last Layer"
    }
  },
  "3": {
    "inputs": {
      "text": "art by coloring-book-style (distinct black lines on white background) a line drawing, lineart, threshold, linework, .line, MONOCHROME, GREYSCALE",
      "clip": [
        "10",
        1
      ]
    },
    "class_type": "CLIPTextEncode",
    "_meta": {
      "title": "CLIP Text Encode (Prompt)"
    }
  },
  "4": {
    "inputs": {
      "text": "(shading, shadows, gray), (scribbles, scratches, dots, splatter), signature, watermark, logo, photo, 3d (worst quality, low quality), noise, face, 1girl, drawing, hair, border",
      "clip": [
        "10",
        1
      ]
    },
    "class_type": "CLIPTextEncode",
    "_meta": {
      "title": "CLIP Text Encode (Prompt)"
    }
  },
  "5": {
    "inputs": {
      "seed": 410390060505237,
      "steps": 30,
      "cfg": 7.98,
      "sampler_name": "euler",
      "scheduler": "normal",
      "denoise": 0.9400000000000001,
      "model": [
        "10",
        0
      ],
      "positive": [
        "16",
        0
      ],
      "negative": [
        "16",
        1
      ],
      "latent_image": [
        "59",
        0
      ]
    },
    "class_type": "KSampler",
    "_meta": {
      "title": "KSampler"
    }
  },
  "7": {
    "inputs": {
      "samples": [
        "5",
        0
      ],
      "vae": [
        "8",
        0
      ]
    },
    "class_type": "VAEDecode",
    "_meta": {
      "title": "VAE Decode"
    }
  },
  "8": {
    "inputs": {
      "vae_name": "vae-ft-mse-840000-ema-pruned.safetensors"
    },
    "class_type": "VAELoader",
    "_meta": {
      "title": "Load VAE"
    }
  },
  "10": {
    "inputs": {
      "lora_name": "Outline.safetensors",
      "strength_model": 0.7000000000000001,
      "strength_clip": 1,
      "model": [
        "19",
        0
      ],
      "clip": [
        "19",
        1
      ]
    },
    "class_type": "LoraLoader",
    "_meta": {
      "title": "Load LoRA"
    }
  },
  "13": {
    "inputs": {
      "control_net_name": "control_v11p_sd15_lineart_fp16.safetensors"
    },
    "class_type": "ControlNetLoader",
    "_meta": {
      "title": "Load ControlNet Model"
    }
  },
  "16": {
    "inputs": {
      "strength": 1.5,
      "start_percent": 0.05,
      "end_percent": 1,
      "positive": [
        "3",
        0
      ],
      "negative": [
        "4",
        0
      ],
      "control_net": [
        "13",
        0
      ],
      "image": [
        "182",
        0
      ]
    },
    "class_type": "ControlNetApplyAdvanced",
    "_meta": {
      "title": "Apply ControlNet (Advanced)"
    }
  },
  "19": {
    "inputs": {
      "lora_name": "Lineart.safetensors",
      "strength_model": 0.7000000000000001,
      "strength_clip": 1,
      "model": [
        "1",
        0
      ],
      "clip": [
        "2",
        0
      ]
    },
    "class_type": "LoraLoader",
    "_meta": {
      "title": "Load LoRA"
    }
  },
  "57": {
    "inputs": {
      "max_width": 1024,
      "max_height": 1024,
      "min_width": 0,
      "min_height": 0,
      "crop_if_required": "no",
      "images": [
        "73",
        0
      ]
    },
    "class_type": "ConstrainImage|pysssss",
    "_meta": {
      "title": "Constrain Image 🐍"
    }
  },
  "59": {
    "inputs": {
      "pixels": [
        "57",
        0
      ],
      "vae": [
        "8",
        0
      ]
    },
    "class_type": "VAEEncode",
    "_meta": {
      "title": "VAE Encode"
    }
  },
  "73": {
    "inputs": {
      "width": [
        "193",
        1
      ],
      "height": [
        "193",
        2
      ],
      "batch_size": 1,
      "color": 16777215
    },
    "class_type": "EmptyImage",
    "_meta": {
      "title": "EmptyImage"
    }
  },
  "89": {
    "inputs": {
      "max_width": 1024,
      "max_height": 1024,
      "min_width": 0,
      "min_height": 0,
      "crop_if_required": "no",
      "images": [
        "117",
        0
      ]
    },
    "class_type": "ConstrainImage|pysssss",
    "_meta": {
      "title": "Constrain Image 🐍"
    }
  },
  "91": {
    "inputs": {
      "blend_factor": 1,
      "blend_mode": "multiply",
      "image1": [
        "96",
        0
      ],
      "image2": [
        "137",
        0
      ]
    },
    "class_type": "ImageBlend",
    "_meta": {
      "title": "ImageBlend"
    }
  },
  "92": {
    "inputs": {
      "filename_prefix": "ComfyUI",
      "images": [
        "104",
        0
      ]
    },
    "class_type": "SaveImage",
    "_meta": {
      "title": "Save Image"
    }
  },
  "96": {
    "inputs": {
      "black_level": 55.1,
      "mid_level": 90.10000000000001,
      "white_level": 180,
      "image": [
        "7",
        0
      ]
    },
    "class_type": "Image Levels Adjustment",
    "_meta": {
      "title": "Image Levels Adjustment"
    }
  },
  "102": {
    "inputs": {
      "upscale_model": [
        "103",
        0
      ],
      "image": [
        "91",
        0
      ]
    },
    "class_type": "ImageUpscaleWithModel",
    "_meta": {
      "title": "Upscale Image (using Model)"
    }
  },
  "103": {
    "inputs": {
      "model_name": "UniversalUpscalerV2Neutral.pth"
    },
    "class_type": "UpscaleModelLoader",
    "_meta": {
      "title": "Load Upscale Model"
    }
  },
  "104": {
    "inputs": {
      "upscale_method": "bicubic",
      "scale_by": 1,
      "image": [
        "102",
        0
      ]
    },
    "class_type": "ImageScaleBy",
    "_meta": {
      "title": "Upscale Image By"
    }
  },
  "117": {
    "inputs": {
      "resolution": 2048,
      "image": [
        "192",
        0
      ]
    },
    "class_type": "LinkMasterNode",
    "_meta": {
      "title": "Luck"
    }
  },
  "137": {
    "inputs": {
      "black_level": 50.300000000000004,
      "mid_level": 100.80000000000001,
      "white_level": 220.4,
      "image": [
        "89",
        0
      ]
    },
    "class_type": "Image Levels Adjustment",
    "_meta": {
      "title": "Image Levels Adjustment"
    }
  },
  "151": {
    "inputs": {
      "blend_factor": 0.5,
      "blend_mode": "screen",
      "image1": [
        "164",
        0
      ],
      "image2": [
        "170",
        0
      ]
    },
    "class_type": "ImageBlend",
    "_meta": {
      "title": "ImageBlend"
    }
  },
  "164": {
    "inputs": {
      "environment": "natrual",
      "patch_batch_size": 8,
      "resolution": 2048,
      "image": [
        "193",
        0
      ]
    },
    "class_type": "DiffusionEdge_Preprocessor",
    "_meta": {
      "title": "Diffusion Edge (batch size ↑ => speed ↑, VRAM ↑)"
    }
  },
  "170": {
    "inputs": {
      "resolution": 2048,
      "image": [
        "193",
        0
      ]
    },
    "class_type": "Manga2Anime_LineArt_Preprocessor",
    "_meta": {
      "title": "Manga Lineart (aka lineart_anime_denoise)"
    }
  },
  "182": {
    "inputs": {
      "black_level": 0,
      "mid_level": 127.80000000000001,
      "white_level": 124.10000000000001,
      "image": [
        "151",
        0
      ]
    },
    "class_type": "Image Levels Adjustment",
    "_meta": {
      "title": "Image Levels Adjustment"
    }
  },
  "192": {
    "inputs": {
      "n_clusters": "Normal",
      "resolution": 2048,
      "image": [
        "193",
        0
      ]
    },
    "class_type": "SuckerPunch",
    "_meta": {
      "title": "Dumb"
    }
  },
  "193": {
    "inputs": {
      "verbose": "true",
      "image": "00028-[ (art by Silvestro Lega_1.3) _art by Franz Sedlacek], (downward-angle) (from above) hyperrealistic, a narrow gothic lantern wit.jpg",
      "upload": "image"
    },
    "class_type": "Image Load TTK",
    "_meta": {
      "title": "Image Load TTK"
    }
  }
}